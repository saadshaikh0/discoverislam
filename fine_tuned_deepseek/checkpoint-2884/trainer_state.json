{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9996966939642099,
  "eval_steps": 500,
  "global_step": 2884,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0173317734737207,
      "grad_norm": 7.12909460067749,
      "learning_rate": 2.951109570041609e-05,
      "loss": 22.7008,
      "step": 50
    },
    {
      "epoch": 0.0346635469474414,
      "grad_norm": 13.017560005187988,
      "learning_rate": 2.9001386962552014e-05,
      "loss": 20.8987,
      "step": 100
    },
    {
      "epoch": 0.051995320421162096,
      "grad_norm": 30.120391845703125,
      "learning_rate": 2.8491678224687934e-05,
      "loss": 16.7004,
      "step": 150
    },
    {
      "epoch": 0.0693270938948828,
      "grad_norm": 25.513370513916016,
      "learning_rate": 2.7971567267683775e-05,
      "loss": 7.5855,
      "step": 200
    },
    {
      "epoch": 0.0866588673686035,
      "grad_norm": 2.227626085281372,
      "learning_rate": 2.7451456310679612e-05,
      "loss": 1.2436,
      "step": 250
    },
    {
      "epoch": 0.10399064084232419,
      "grad_norm": 1.8262474536895752,
      "learning_rate": 2.6931345353675453e-05,
      "loss": 0.8576,
      "step": 300
    },
    {
      "epoch": 0.12132241431604489,
      "grad_norm": 3.9489645957946777,
      "learning_rate": 2.641123439667129e-05,
      "loss": 0.7018,
      "step": 350
    },
    {
      "epoch": 0.1386541877897656,
      "grad_norm": 4.134139537811279,
      "learning_rate": 2.589112343966713e-05,
      "loss": 0.6928,
      "step": 400
    },
    {
      "epoch": 0.1559859612634863,
      "grad_norm": 1.9498056173324585,
      "learning_rate": 2.5371012482662966e-05,
      "loss": 0.6018,
      "step": 450
    },
    {
      "epoch": 0.173317734737207,
      "grad_norm": 1.8340590000152588,
      "learning_rate": 2.4850901525658807e-05,
      "loss": 0.6053,
      "step": 500
    },
    {
      "epoch": 0.1906495082109277,
      "grad_norm": 3.369537830352783,
      "learning_rate": 2.4330790568654648e-05,
      "loss": 0.54,
      "step": 550
    },
    {
      "epoch": 0.20798128168464838,
      "grad_norm": 2.133857488632202,
      "learning_rate": 2.3810679611650485e-05,
      "loss": 0.5369,
      "step": 600
    },
    {
      "epoch": 0.22531305515836908,
      "grad_norm": 1.5809025764465332,
      "learning_rate": 2.3290568654646326e-05,
      "loss": 0.5801,
      "step": 650
    },
    {
      "epoch": 0.24264482863208978,
      "grad_norm": 7.163482189178467,
      "learning_rate": 2.2770457697642164e-05,
      "loss": 0.5834,
      "step": 700
    },
    {
      "epoch": 0.2599766021058105,
      "grad_norm": 1.7497904300689697,
      "learning_rate": 2.2250346740638005e-05,
      "loss": 0.5565,
      "step": 750
    },
    {
      "epoch": 0.2773083755795312,
      "grad_norm": 5.920299053192139,
      "learning_rate": 2.1730235783633842e-05,
      "loss": 0.5682,
      "step": 800
    },
    {
      "epoch": 0.29464014905325187,
      "grad_norm": 3.50022554397583,
      "learning_rate": 2.1210124826629683e-05,
      "loss": 0.562,
      "step": 850
    },
    {
      "epoch": 0.3119719225269726,
      "grad_norm": 5.489014625549316,
      "learning_rate": 2.069001386962552e-05,
      "loss": 0.5224,
      "step": 900
    },
    {
      "epoch": 0.32930369600069326,
      "grad_norm": 2.15659499168396,
      "learning_rate": 2.016990291262136e-05,
      "loss": 0.5571,
      "step": 950
    },
    {
      "epoch": 0.346635469474414,
      "grad_norm": 6.632589340209961,
      "learning_rate": 1.96497919556172e-05,
      "loss": 0.5512,
      "step": 1000
    },
    {
      "epoch": 0.36396724294813465,
      "grad_norm": 4.089434623718262,
      "learning_rate": 1.912968099861304e-05,
      "loss": 0.5157,
      "step": 1050
    },
    {
      "epoch": 0.3812990164218554,
      "grad_norm": 8.768019676208496,
      "learning_rate": 1.8609570041608874e-05,
      "loss": 0.5557,
      "step": 1100
    },
    {
      "epoch": 0.39863078989557604,
      "grad_norm": 4.569929599761963,
      "learning_rate": 1.8089459084604715e-05,
      "loss": 0.5012,
      "step": 1150
    },
    {
      "epoch": 0.41596256336929677,
      "grad_norm": 5.306507110595703,
      "learning_rate": 1.7569348127600553e-05,
      "loss": 0.4748,
      "step": 1200
    },
    {
      "epoch": 0.43329433684301744,
      "grad_norm": 1.5587623119354248,
      "learning_rate": 1.7049237170596393e-05,
      "loss": 0.4939,
      "step": 1250
    },
    {
      "epoch": 0.45062611031673816,
      "grad_norm": 3.5039560794830322,
      "learning_rate": 1.6529126213592234e-05,
      "loss": 0.506,
      "step": 1300
    },
    {
      "epoch": 0.4679578837904589,
      "grad_norm": 3.7396774291992188,
      "learning_rate": 1.6009015256588072e-05,
      "loss": 0.5107,
      "step": 1350
    },
    {
      "epoch": 0.48528965726417955,
      "grad_norm": 3.8560235500335693,
      "learning_rate": 1.5488904299583913e-05,
      "loss": 0.5241,
      "step": 1400
    },
    {
      "epoch": 0.5026214307379002,
      "grad_norm": 2.4117279052734375,
      "learning_rate": 1.496879334257975e-05,
      "loss": 0.5134,
      "step": 1450
    },
    {
      "epoch": 0.519953204211621,
      "grad_norm": 1.5567421913146973,
      "learning_rate": 1.444868238557559e-05,
      "loss": 0.5558,
      "step": 1500
    },
    {
      "epoch": 0.5372849776853417,
      "grad_norm": 3.3917627334594727,
      "learning_rate": 1.3928571428571429e-05,
      "loss": 0.4836,
      "step": 1550
    },
    {
      "epoch": 0.5546167511590624,
      "grad_norm": 11.643217086791992,
      "learning_rate": 1.3408460471567268e-05,
      "loss": 0.4937,
      "step": 1600
    },
    {
      "epoch": 0.571948524632783,
      "grad_norm": 4.6628737449646,
      "learning_rate": 1.2888349514563106e-05,
      "loss": 0.5272,
      "step": 1650
    },
    {
      "epoch": 0.5892802981065037,
      "grad_norm": 4.599273681640625,
      "learning_rate": 1.2368238557558946e-05,
      "loss": 0.5232,
      "step": 1700
    },
    {
      "epoch": 0.6066120715802245,
      "grad_norm": 3.7309558391571045,
      "learning_rate": 1.1848127600554786e-05,
      "loss": 0.522,
      "step": 1750
    },
    {
      "epoch": 0.6239438450539452,
      "grad_norm": 3.42429780960083,
      "learning_rate": 1.1328016643550625e-05,
      "loss": 0.4842,
      "step": 1800
    },
    {
      "epoch": 0.6412756185276658,
      "grad_norm": 3.2954044342041016,
      "learning_rate": 1.0807905686546464e-05,
      "loss": 0.4813,
      "step": 1850
    },
    {
      "epoch": 0.6586073920013865,
      "grad_norm": 19.9638729095459,
      "learning_rate": 1.0287794729542303e-05,
      "loss": 0.5248,
      "step": 1900
    },
    {
      "epoch": 0.6759391654751072,
      "grad_norm": 4.526304244995117,
      "learning_rate": 9.767683772538143e-06,
      "loss": 0.4724,
      "step": 1950
    },
    {
      "epoch": 0.693270938948828,
      "grad_norm": 2.343731164932251,
      "learning_rate": 9.24757281553398e-06,
      "loss": 0.5458,
      "step": 2000
    },
    {
      "epoch": 0.7106027124225487,
      "grad_norm": 2.3204092979431152,
      "learning_rate": 8.72746185852982e-06,
      "loss": 0.5448,
      "step": 2050
    },
    {
      "epoch": 0.7279344858962693,
      "grad_norm": 2.98624849319458,
      "learning_rate": 8.207350901525659e-06,
      "loss": 0.5181,
      "step": 2100
    },
    {
      "epoch": 0.74526625936999,
      "grad_norm": 2.044009208679199,
      "learning_rate": 7.687239944521498e-06,
      "loss": 0.5051,
      "step": 2150
    },
    {
      "epoch": 0.7625980328437107,
      "grad_norm": 2.5173749923706055,
      "learning_rate": 7.167128987517337e-06,
      "loss": 0.5343,
      "step": 2200
    },
    {
      "epoch": 0.7799298063174315,
      "grad_norm": 4.1110005378723145,
      "learning_rate": 6.647018030513177e-06,
      "loss": 0.5461,
      "step": 2250
    },
    {
      "epoch": 0.7972615797911521,
      "grad_norm": 5.516086578369141,
      "learning_rate": 6.1269070735090154e-06,
      "loss": 0.5206,
      "step": 2300
    },
    {
      "epoch": 0.8145933532648728,
      "grad_norm": 2.684109687805176,
      "learning_rate": 5.606796116504855e-06,
      "loss": 0.506,
      "step": 2350
    },
    {
      "epoch": 0.8319251267385935,
      "grad_norm": 2.272444248199463,
      "learning_rate": 5.086685159500694e-06,
      "loss": 0.5025,
      "step": 2400
    },
    {
      "epoch": 0.8492569002123143,
      "grad_norm": 1.7172163724899292,
      "learning_rate": 4.566574202496532e-06,
      "loss": 0.487,
      "step": 2450
    },
    {
      "epoch": 0.8665886736860349,
      "grad_norm": 1.9733790159225464,
      "learning_rate": 4.0464632454923715e-06,
      "loss": 0.4907,
      "step": 2500
    },
    {
      "epoch": 0.8839204471597556,
      "grad_norm": 2.8746018409729004,
      "learning_rate": 3.526352288488211e-06,
      "loss": 0.5112,
      "step": 2550
    },
    {
      "epoch": 0.9012522206334763,
      "grad_norm": 6.272216320037842,
      "learning_rate": 3.00624133148405e-06,
      "loss": 0.4842,
      "step": 2600
    },
    {
      "epoch": 0.918583994107197,
      "grad_norm": 3.256387233734131,
      "learning_rate": 2.486130374479889e-06,
      "loss": 0.4956,
      "step": 2650
    },
    {
      "epoch": 0.9359157675809178,
      "grad_norm": 2.4701461791992188,
      "learning_rate": 1.9660194174757284e-06,
      "loss": 0.4687,
      "step": 2700
    },
    {
      "epoch": 0.9532475410546384,
      "grad_norm": 3.152686834335327,
      "learning_rate": 1.4459084604715674e-06,
      "loss": 0.4762,
      "step": 2750
    },
    {
      "epoch": 0.9705793145283591,
      "grad_norm": 3.8429853916168213,
      "learning_rate": 9.257975034674064e-07,
      "loss": 0.4908,
      "step": 2800
    },
    {
      "epoch": 0.9879110880020798,
      "grad_norm": 2.2288544178009033,
      "learning_rate": 4.056865464632455e-07,
      "loss": 0.486,
      "step": 2850
    }
  ],
  "logging_steps": 50,
  "max_steps": 2884,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9671256822657843e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
